{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_fix_dims(ds):\n",
    "    '''\n",
    "    Fix time dimensions to be easier to call, put time in hours and put x and y in km\n",
    "    '''\n",
    "    if \"time_fine\" not in ds.variables:\n",
    "        ds = ds.rename({str(u'time_series_4500_1800.0'): 'time_coarse', str(u'time_series_75_60.0'): 'time_fine', str(u'time_series_75_1800.0'): 'time_mid'})\n",
    "    ds['time_coarse']=ds.time_coarse/3600\n",
    "    ds['time_mid']=ds.time_mid/3600\n",
    "    ds['time_fine']=ds.time_fine/3600\n",
    "    ds['x'] = ds.x.astype(float)/(35)\n",
    "    ds['y'] = ds.y.astype(float)/(35)\n",
    "    return ds\n",
    "\n",
    "def surf_pre_calc(ds, when):\n",
    "    '''\n",
    "    surface precip domain mean in mm and mean over the simulation time\n",
    "    '''\n",
    "    if when == \"beginning\":\n",
    "        surface_precip_mean = ds.surface_precip_mean[fine_spin:]*1000\n",
    "        surface_precip_mean = surface_precip_mean.mean()/(ds.time_fine[-1]-ds.time_fine[fine_spin])\n",
    "    elif when == \"end\":\n",
    "        surface_precip_mean = ds.surface_precip_mean[-fine_ave:]*1000\n",
    "        surface_precip_mean = surface_precip_mean.mean()/(ds.time_fine[-1]-ds.time_fine[fine_ave])\n",
    "    return surface_precip_mean\n",
    "\n",
    "def rwp_calc(ds, when):\n",
    "    '''\n",
    "    rwp domain mean in g m^(-2) and mean over the simulation time\n",
    "    '''\n",
    "    if when == \"beginning\":\n",
    "        rwp_mean = ds.RWP_mean[fine_spin:]*1000\n",
    "        rwp_mean = rwp_mean.mean()\n",
    "    elif when == \"end\":\n",
    "        rwp_mean = ds.RWP_mean[-fine_ave:]*1000\n",
    "        rwp_end_mean = rwp_mean.mean()\n",
    "    return rwp_mean\n",
    "\n",
    "def rain(ds):\n",
    "    rwp_mean = rwp_calc(ds, \"beginning\")\n",
    "    rwp_end_mean = rwp_calc(ds, \"end\")\n",
    "    sp_mean = surf_pre_calc(ds, \"beginning\")\n",
    "    sp_end_mean = surf_pre_calc(ds, \"end\")\n",
    "    return [rwp_mean.item(), rwp_end_mean.item(), sp_mean.item(), sp_end_mean.item()]\n",
    "\n",
    "def tke_calc(ds): \n",
    "    tke_mean = ds.reske_mean + ds.subke_mean\n",
    "    time_mean = ds.reske_mean[ds.reske_mean.dims[0]].values\n",
    "    return tke_mean, time_mean\n",
    "\n",
    "def lwp_cloud_calc(lmmr, lwp):   \n",
    "    cloudy_lwp = []\n",
    "    t = []\n",
    "    lwp_masked_arrs=[]\n",
    "    for m in range(len(lmmr)):\n",
    "        col_mask = layer_cloud_mask(lmmr, m)\n",
    "        arr_mask = col_mask.values\n",
    "        lwp_masked = lwp[m].where(arr_mask==1)\n",
    "        lwp_masked_arrs.append(lwp_masked*1000)\n",
    "        cloud_lwp_mean = lwp_masked.mean(axis=(0,1))\n",
    "        cloudy_lwp.append(cloud_lwp_mean.item()*1000)\n",
    "        t.append(lmmr[m][lmmr.dims[0]].item())\n",
    "\n",
    "    lwp_masked = lwp_masked*1000\n",
    "    return cloudy_lwp, t, lwp_masked, lwp_masked_arrs\n",
    "\n",
    "def lwp_cloud(ds):\n",
    "    if include_spinup == True:\n",
    "        lwp = ds.lwp\n",
    "        lmmr = ds.q_cloud_liquid_mass\n",
    "        time_arr = ds.time_coarse\n",
    "    else:\n",
    "        lwp = ds.lwp[coarse_spin:]\n",
    "        lmmr = ds.q_cloud_liquid_mass[coarse_spin:]\n",
    "        time_arr = ds.time_coarse[coarse_spin:]\n",
    "    \n",
    "    cloudy_lwp, times, lwp_masked_last, lwp_masked_arrs = lwp_cloud_calc(lmmr, lwp)\n",
    "    lwp_cloud_mean = np.mean(cloudy_lwp[-coarse_ave:])\n",
    "    lwp_cloud_teme = (np.mean(cloudy_lwp[-coarse_ave:])-np.mean(cloudy_lwp[:coarse_ave]))/(time_arr[-1] - time_arr[0])\n",
    "    tendency = calc_tendency(cloudy_lwp, times)\n",
    "    return [lwp_cloud_mean, lwp_cloud_teme],cloudy_lwp, tendency,times, lwp_masked_last, lwp_masked_arrs\n",
    "\n",
    "def calc_tendency(dataarray, *times):\n",
    "    tendency=[]\n",
    "    if times:\n",
    "        tseries = times[0]\n",
    "    else:\n",
    "        tseries = dataarray[dataarray.dims[0]].values\n",
    "        dataarray = dataarray.values\n",
    "    for t_ind in range(1, len(dataarray), 1):\n",
    "        c_step = dataarray[t_ind]\n",
    "        p_step = dataarray[t_ind - 1]\n",
    "        dx = (c_step) - (p_step)\n",
    "        t = tseries[t_ind] - tseries[t_ind-1]\n",
    "        if t != 0:\n",
    "            tendency.append(dx/t)\n",
    "        else:\n",
    "            tendency.append(dx/0.01)\n",
    "    return tendency\n",
    "\n",
    "def column_cloud_fraction(lmmr):\n",
    "    cloud_frac=[]\n",
    "    t =[]\n",
    "    for m in range(len(lmmr)):\n",
    "        col_mask = layer_cloud_mask(lmmr, m)\n",
    "        total = col_mask.sum(axis=(0,1))\n",
    "        f = total.item()/(250*250)\n",
    "        cloud_frac.append(f)\n",
    "        t.append(lmmr[m][lmmr.dims[0]].item())\n",
    "    return cloud_frac, t\n",
    "\n",
    "def clfrac(ds):\n",
    "    if include_spinup == True:\n",
    "        lmmr = ds.q_cloud_liquid_mass\n",
    "        time_arr = ds.time_coarse\n",
    "    else:\n",
    "        lmmr = ds.q_cloud_liquid_mass[coarse_spin:]\n",
    "        time_arr = ds.time_coarse[coarse_spin:]\n",
    "\n",
    "    cloud_frac, times = column_cloud_fraction(lmmr)\n",
    "    cloud_frac_mean = np.mean(cloud_frac[-coarse_ave:])\n",
    "    cloud_frac_teme = (np.mean(cloud_frac[-coarse_ave:]) - np.mean(cloud_frac[:coarse_ave]))/(time_arr[-1] - time_arr[0])\n",
    "    tendency = calc_tendency(cloud_frac, times)\n",
    "    return [cloud_frac_mean, cloud_frac_teme], cloud_frac, tendency, times\n",
    "\n",
    "def layer_cloud_mask(dataarray, time):\n",
    "    '''\n",
    "    Applies mask to each timestep and sums\n",
    "    '''\n",
    "    for n in range(110):\n",
    "        layer = dataarray[time,:,:,n]\n",
    "        dataarray[time,:,:,n] = layer.where(layer.values<1e-5,1).where(layer.values>1e-5,0)\n",
    "    col_sum = dataarray[time].sum(axis=2,skipna=True)\n",
    "    col_mask = col_sum.where(col_sum.values<1,1)\n",
    "    return col_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load design and set paths to data\n",
    "nd = \"low_nd\"  # \"low_nd\" or \"high_nd\"\n",
    "ppe_path   = \"/gws/nopw/j04/carisma/eers/dycoms/{}/PPE/ppe\".format(nd)\n",
    "val_path   = \"/gws/nopw/j04/carisma/eers/dycoms/{}/VAL/val\".format(nd)\n",
    "extra_path = \"/gws/nopw/j04/carisma/eers/dycoms/{}/EXTRA/extra\".format(nd)\n",
    "base_path  = \"/gws/nopw/j04/carisma/eers/dycoms/{}/BASE/base/base.nc\".format(nd)\n",
    "design       = np.loadtxt(\"designs/EmulatorInputsDesign2D.csv\",delimiter=\",\", skiprows=1)\n",
    "validation   = np.loadtxt(\"designs/ValidationInputsDesign2D.csv\", delimiter=\",\", skiprows=1)\n",
    "extra_design = np.loadtxt(\"designs/extra_points.csv\",delimiter=\",\")\n",
    "base = np.array([[-7.5, 8.5]])\n",
    "\n",
    "ppe_no   = 20\n",
    "val_no   = 8\n",
    "extra_no = 6\n",
    "base_no  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = OrderedDict()\n",
    "od[\"ppe\"]   = [ppe_no, ppe_path, design]\n",
    "od[\"val\"]   = [val_no, val_path, validation]\n",
    "od[\"extra\"] = [extra_no, extra_path, extra_design]\n",
    "od[\"base\"]  = [base_no, base_path, base]\n",
    "\n",
    "### Initialise np arrays ###\n",
    "mean = np.empty((ppe_no+val_no+extra_no+base_no, 3))\n",
    "teme = np.empty((ppe_no+val_no+extra_no+base_no, 3))\n",
    "\n",
    "arrays = [mean, teme]\n",
    "\n",
    "rwp     = np.empty((ppe_no+val_no+extra_no+base_no, 3))\n",
    "rwp_end = np.empty((ppe_no+val_no+extra_no+base_no, 3))\n",
    "surface_precip     = np.empty((ppe_no+val_no+extra_no+base_no, 3))\n",
    "surface_precip_end = np.empty((ppe_no+val_no+extra_no+base_no, 3))\n",
    "\n",
    "rain_arrays = [rwp, rwp_end, surface_precip, surface_precip_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Options ###\n",
    "include_spinup = False # See fine_spin and coarse_spin for setup\n",
    "\n",
    "coarse_spin = 2   # 1 hour = 1, 2 hours = 2\n",
    "fine_spin   = 111 # 1 hour = 55, 2 hours = 111\n",
    "coarse_ave  = 3\n",
    "fine_ave    = 111  \n",
    "\n",
    "### Loop through PPE datasets and calculate the in-cloud LWP, cloud fraction or rain mass-mixing ratio ###\n",
    "calc    = 'lwp_cloud'      # options: 'lwp_cloud', 'cloud_frac', 'rain'\n",
    "type_nd = \"lwp_low\"  # [lwp/cf/rain]_[low/high] but do lwp_total_low/high if doing lwp_total.\n",
    "i=0\n",
    "\n",
    "type_timeseries=[]\n",
    "\n",
    "for key in od:\n",
    "    for j in range(od[key][0]):\n",
    "        k = j+1\n",
    "        nc = od[key][1] + str(k) + \"/\" + key + str(k) + \".nc\"\n",
    "        if key=='base':\n",
    "            nc = base_path \n",
    "        ds = xr.open_dataset(nc)\n",
    "        ds = ds_fix_dims(ds)\n",
    "            \n",
    "        if calc == 'lwp_cloud':\n",
    "            output_array, timeseries, tendency, times, lwp_masked_last, lwp_masked_arrs = lwp_cloud(ds)\n",
    "            time_hrs = times\n",
    "\n",
    "            ### uncomment to save top-down scenes\n",
    "            # for step, masked_arr in enumerate(lwp_masked_arrs):\n",
    "            #     np.savetxt(f\"{key}_scenes/scene_{step}.csv\",masked_arr.values, delimiter=',')\n",
    "\n",
    "        elif calc == 'cloud_frac':\n",
    "    \t    output_array, timeseries, tendency, times = clfrac(ds)\n",
    "    \t    time_hrs = times\n",
    "        elif calc == 'rain':\n",
    "    \t    output_array = rain(ds)\n",
    "        else:\n",
    "            print('Select calc')\n",
    "            break\n",
    "\n",
    "        if calc in ['cloud_frac','lwp_cloud']:\n",
    "    \t    for b, array in enumerate(arrays):\n",
    "                array[i, 0] = od[key][2][j][1]   # save theta input value\n",
    "                array[i, 1] = od[key][2][j][0]   # save qt input value\n",
    "                array[i, 2] = output_array[b]    # save output value\n",
    "        elif calc == 'rain':\n",
    "    \t    for b, array in enumerate(rain_arrays):\n",
    "    \t        array[i, 0] = od[key][2][j][1]   # save theta input value\n",
    "    \t        array[i, 1] = od[key][2][j][0]   # save qt input value\n",
    "    \t        array[i, 2] = output_array[b]    # save output value\n",
    "\n",
    "        ### uncomment to save timeseries\n",
    "        # if key=='ppe':\n",
    "        #     type_timeseries.append(timeseries)\n",
    "        # elif key=='base':\n",
    "        #     base=timeseries\n",
    "        # np.savetxt('./timeseries/{}/{}{}_timeseries.csv'.format(type_nd,key,str(k)),timeseries,delimiter=',')   # need type_nd instead of calc if not doing lwp_cloud\n",
    "        # np.savetxt('./timeseries/{}/{}{}_times.csv'.format(type_nd,key,str(k)),time_hrs,delimiter=',')\n",
    "        ds.close()\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc == 'rain':\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_rwp.csv\".format(nd, calc), rain_arrays[0], delimiter=\",\")\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_rwp_end.csv\".format(nd, calc), rain_arrays[1], delimiter=\",\")\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_surfpre.csv\".format(nd,calc), rain_arrays[2], delimiter=\",\")\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_surfpre_end.csv\".format(nd,calc), rain_arrays[3], delimiter=\",\")\n",
    "else:\n",
    "    print(\"Saving..\")\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_mean.csv\".format(nd,calc), arrays[0], delimiter=\",\")\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_teme.csv\".format(nd,calc), arrays[1], delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do calculations for initial-condition ensembles\n",
    "#calc='cloud_frac'\n",
    "calc='lwp_cloud'\n",
    "\n",
    "type_nd = \"lwp_cloud_low\"\n",
    "### Variability ###\n",
    "var_path = \"/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/\" #.format(nd)\n",
    "points = ['ppe3','ppe9','ppe11','ppe14','ppe15','ppe17','ppe18','ppe19','ppe20']\n",
    "\n",
    "### Create lists ###\n",
    "e_mean=[]\n",
    "e_teme=[]\n",
    "i=0\n",
    "for point in points:\n",
    "    for i in range(1,6):# dropped to 4 extras + the 1 original run\n",
    "        if i==(5):\n",
    "            ds=xr.open_dataset(f\"/gws/nopw/j04/carisma/eers/dycoms/low_nd/PPE/{point}/{point}.nc\")\n",
    "            print('ds_last = original')\n",
    "        else:\n",
    "            name = '{0}_{1}'.format(point, i)\n",
    "            nc = '{0}{1}/{2}.nc'.format(var_path,point,name)\n",
    "            print(nc)\n",
    "            ds = xr.open_dataset(nc)\n",
    "\n",
    "        ds = ds_fix_dims(ds)\n",
    "\n",
    "        elif calc == 'lwp_cloud':\n",
    "            output_array, timeseries, tendency, times, lwp_masked_last, lwp_diff = lwp_cloud(ds)\n",
    "            time_hrs = times\n",
    "            ### uncomment to save top-down scenes\n",
    "            # np.savetxt(\"lwp_scenes_last/lnd_lwp_scene_last_%s%s.csv\"%(point,i),lwp_masked_last.values, delimiter=',')\n",
    "            e_mean.append(output_array[0])\n",
    "            e_teme.append(output_array[1])\n",
    "        elif calc == 'cloud_frac':\n",
    "            output_array, timeseries, tendency, times = clfrac(ds)\n",
    "            time_hrs = times\n",
    "            e_mean.append(output_array[0])\n",
    "            e_teme.append(output_array[1])\n",
    "        else:\n",
    "            print(\"Select calc\")\n",
    "            break\n",
    "\n",
    "        # np.savetxt('./timeseries/{}/{}{}_timeseries.csv'.format(type_nd,point,str(i+1)), timeseries,delimiter=',')\n",
    "        # np.savetxt('./timeseries/{}/{}{}_times.csv'.format(type_nd,point,str(i+1)),time_hrs,delimiter=',')\n",
    "\n",
    "    #print(point + ' finished')    \n",
    "\n",
    "elif calc=='cloud_frac':\n",
    "    out_list = [e_mean, e_teme]\n",
    "elif calc=='lwp_cloud':\n",
    "    out_list = [e_mean,e_teme]\n",
    "out_arr_T = np.array(out_list).T\n",
    "np.savetxt('ensemble_{}_mean.csv'.format(calc), out_arr_T, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
