{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import rc\n",
    "# rc('text', usetex=True)\n",
    "# rc('font', **{'family': 'serif', 'serif': ['Computer Modern'], 'size': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_fix_dims(ds):\n",
    "    '''\n",
    "    Fix time dimensions to be easier to call, put time in hours and put x and y in km\n",
    "    '''\n",
    "    if \"time_fine\" not in ds.variables:\n",
    "        ds = ds.rename({str(u'time_series_4500_1800.0'): 'time_coarse', str(u'time_series_75_60.0'): 'time_fine', str(u'time_series_75_1800.0'): 'time_mid'})\n",
    "    ds['time_coarse']=ds.time_coarse/3600\n",
    "    ds['time_mid']=ds.time_mid/3600\n",
    "    ds['time_fine']=ds.time_fine/3600\n",
    "    ds['x'] = ds.x.astype(float)/(35)\n",
    "    ds['y'] = ds.y.astype(float)/(35)\n",
    "    return ds\n",
    "\n",
    "def surf_pre_calc(ds):\n",
    "    '''\n",
    "    surface precip domain mean in mm and mean over the simulation time\n",
    "    '''\n",
    "    surface_precip_mean = ds.surface_precip_mean[fine_spin:]*1000\n",
    "    surface_precip_mean = surface_precip_mean.mean()/(ds.time_fine[-1]-ds.time_fine[fine_spin])\n",
    "    return surface_precip_mean\n",
    "\n",
    "def surf_pre_calc_end(ds):\n",
    "    '''\n",
    "    surface precip domain mean in mm and mean over the simulation time\n",
    "    '''\n",
    "    if when==\"end\n",
    "    surface_precip_mean = ds.surface_precip_mean[-fine_ave:]*1000\n",
    "    surface_precip_end_mean = surface_precip_mean.mean()/(ds.time_fine[-1]-ds.time_fine[fine_ave])\n",
    "    return surface_precip_end_mean\n",
    "\n",
    "def rwp_calc(ds):\n",
    "    '''\n",
    "    rwp domain mean in g m^(-2) and mean over the simulation time\n",
    "    '''\n",
    "    rwp_mean = ds.RWP_mean[fine_spin:]*1000\n",
    "    rwp_mean = rwp_mean.mean()\n",
    "    return rwp_mean\n",
    "\n",
    "def rwp_calc_end(ds):\n",
    "    '''\n",
    "    rwp domain mean in g m^(-2) and mean over the simulation time\n",
    "    '''\n",
    "    rwp_mean = ds.RWP_mean[-fine_ave:]*1000\n",
    "    rwp_end_mean = rwp_mean.mean()\n",
    "    return rwp_end_mean\n",
    "\n",
    "def rain(ds):\n",
    "    rwp_mean = rwp_calc(ds)\n",
    "    rwp_end_mean = rwp_calc_end(ds)\n",
    "    sp_mean = surf_pre_calc(ds)\n",
    "    sp_end_mean = surf_pre_calc_end(ds)\n",
    "    return [rwp_mean.item(), rwp_end_mean.item(), sp_mean.item(), sp_end_mean.item()]\n",
    "\n",
    "def tke_calc(ds): \n",
    "    tke_mean = ds.reske_mean + ds.subke_mean\n",
    "    time_mean = ds.reske_mean[ds.reske_mean.dims[0]].values\n",
    "    return tke_mean, time_mean\n",
    "\n",
    "def lwp_total(ds):\n",
    "    if include_spinup == True:\n",
    "        lwp = ds.LWP_mean*1000\n",
    "        time_arr = ds.time_fine\n",
    "    else:\n",
    "        lwp = ds.LWP_mean[fine_spin:]*1000\n",
    "        time_arr = ds.time_fine[fine_spin:]\n",
    "    \n",
    "    lwp = lwp.where(lwp.values<1e20)\n",
    "    lwp_last = lwp[last]\n",
    "    lwp_mean = np.mean(lwp[-fine_ave:])\n",
    "    lwp_tend = (lwp[last] - lwp[first])/(time_arr[last] - time_arr[first])\n",
    "    lwp_teme = (np.mean(lwp[-fine_ave:]) - np.mean(lwp[:fine_ave]))/(time_arr[last] - time_arr[first])\n",
    "    tendency = calc_tendency(lwp)\n",
    "    return [lwp_last, lwp_mean, lwp_tend, lwp_teme], lwp.values, tendency, lwp[lwp.dims[0]].values\n",
    "\n",
    "def lwp_smooth(ds):\n",
    "    '''\n",
    "    Moving average of the lwp and tendency\n",
    "    '''\n",
    "    if include_spinup == True:\n",
    "        lwp = ds.LWP_mean*1000\n",
    "        time_arr = ds.time_fine\n",
    "    else:\n",
    "        lwp = ds.LWP_mean[fine_spin:]*1000\n",
    "        time_arr = ds.time_fine[fine_spin:]\n",
    "    step = 55\n",
    "    lwp_smooth = []\n",
    "    lwp_tend = []\n",
    "    lwp_tend_smooth = []\n",
    "    i = 0\n",
    "    for l in range(1, len(lwp)):\n",
    "        lwp_tend.append((lwp[l] - lwp[l-1])/(lwp.time_fine[l] - lwp.time_fine[l-1]))\n",
    "        if l>step-1:\n",
    "            lwp_smooth.append(lwp[l-step:l].mean())\n",
    "            if i>0:\n",
    "                lwp_tend_smooth.append((lwp_smooth[i] - lwp_smooth[i-1])/(lwp.time_fine[l] - lwp.time_fine[l-1]))\n",
    "                i+=1\n",
    "    return [lwp_smooth[-1], np.mean(lwp_smooth[-55:]), lwp_tend[-1], np.mean(lwp_tend), (lwp_smooth[-1]-lwp_smooth[0])/(time_arr[last] - time_arr[first])]\n",
    "\n",
    "def lwp_cloud_calc(lmmr, lwp):   \n",
    "    cloudy_lwp = []\n",
    "    t = []\n",
    "    lwp_masked_arrs=[]\n",
    "    for m in range(len(lmmr)):\n",
    "        col_mask = layer_cloud_mask(lmmr, m)\n",
    "        arr_mask = col_mask.values\n",
    "        lwp_masked = lwp[m].where(arr_mask==1)\n",
    "        lwp_masked_arrs.append(lwp_masked*1000)\n",
    "        cloud_lwp_mean = lwp_masked.mean(axis=(0,1))\n",
    "        cloudy_lwp.append(cloud_lwp_mean.item()*1000)\n",
    "        t.append(lmmr[m][lmmr.dims[0]].item())\n",
    "\n",
    "    lwp_masked = lwp_masked*1000\n",
    "    return cloudy_lwp, t, lwp_masked, lwp_masked_arrs\n",
    "\n",
    "def lwp_cloud(ds):\n",
    "    if include_spinup == True:\n",
    "        lwp = ds.lwp\n",
    "        lmmr = ds.q_cloud_liquid_mass\n",
    "        time_arr = ds.time_coarse\n",
    "    else:\n",
    "        lwp = ds.lwp[coarse_spin:]\n",
    "        lmmr = ds.q_cloud_liquid_mass[coarse_spin:]\n",
    "        time_arr = ds.time_coarse[coarse_spin:]\n",
    "    \n",
    "    cloudy_lwp, times, lwp_masked_last, lwp_masked_arrs = lwp_cloud_calc(lmmr, lwp)\n",
    "    lwp_cloud_last = cloudy_lwp[last]\n",
    "    lwp_cloud_mean = np.mean(cloudy_lwp[-coarse_ave:])\n",
    "    lwp_cloud_tend = (cloudy_lwp[last]-cloudy_lwp[first])/(time_arr[last] - time_arr[first])\n",
    "    lwp_cloud_teme = (np.mean(cloudy_lwp[-coarse_ave:])-np.mean(cloudy_lwp[:coarse_ave]))/(time_arr[last] - time_arr[first])\n",
    "    tendency = calc_tendency(cloudy_lwp, times)\n",
    "    return [lwp_cloud_last, lwp_cloud_mean, lwp_cloud_tend, lwp_cloud_teme],cloudy_lwp,tendency,times, lwp_masked_last, lwp_masked_arrs\n",
    "\n",
    "def calc_tendency(dataarray, *times):\n",
    "    tendency=[]\n",
    "    if times:\n",
    "        tseries = times[0]\n",
    "    else:\n",
    "        tseries = dataarray[dataarray.dims[0]].values\n",
    "        dataarray = dataarray.values\n",
    "    for t_ind in range(1, len(dataarray), 1):\n",
    "        c_step = dataarray[t_ind]\n",
    "        p_step = dataarray[t_ind - 1]\n",
    "        dx = (c_step) - (p_step)\n",
    "        t = tseries[t_ind] - tseries[t_ind-1]\n",
    "        if t != 0:\n",
    "            tendency.append(dx/t)\n",
    "        else:\n",
    "            tendency.append(dx/0.01)\n",
    "    return tendency\n",
    "\n",
    "def column_cloud_fraction(lmmr):\n",
    "    cloud_frac=[]\n",
    "    t =[]\n",
    "    for m in range(len(lmmr)):\n",
    "        col_mask = layer_cloud_mask(lmmr, m)\n",
    "        total = col_mask.sum(axis=(0,1))\n",
    "        f = total.item()/(250*250)\n",
    "        cloud_frac.append(f)\n",
    "        t.append(lmmr[m][lmmr.dims[0]].item())\n",
    "    return cloud_frac, t\n",
    "\n",
    "def clfrac(ds):\n",
    "    if include_spinup == True:\n",
    "        lmmr = ds.q_cloud_liquid_mass\n",
    "        time_arr = ds.time_coarse\n",
    "    else:\n",
    "        lmmr = ds.q_cloud_liquid_mass[coarse_spin:]\n",
    "        time_arr = ds.time_coarse[coarse_spin:]\n",
    "\n",
    "    cloud_frac, times = column_cloud_fraction(lmmr)\n",
    "    cloud_frac_last = cloud_frac[last]\n",
    "    cloud_frac_mean = np.mean(cloud_frac[-coarse_ave:])\n",
    "    cloud_frac_tend = (cloud_frac[last] - cloud_frac[first])/(time_arr[last] - time_arr[first])\n",
    "    cloud_frac_teme = (np.mean(cloud_frac[-coarse_ave:]) - np.mean(cloud_frac[:coarse_ave]))/(time_arr[last] - time_arr[first])\n",
    "    tendency = calc_tendency(cloud_frac, times)\n",
    "    return [cloud_frac_last, cloud_frac_mean, cloud_frac_tend, cloud_frac_teme], cloud_frac, tendency, times\n",
    "\n",
    "def layer_cloud_mask(dataarray, time):\n",
    "    '''\n",
    "    Applies mask to each timestep and sums\n",
    "    '''\n",
    "    for n in range(110):\n",
    "        layer = dataarray[time,:,:,n]\n",
    "        dataarray[time,:,:,n] = layer.where(layer.values<1e-5,1).where(layer.values>1e-5,0)\n",
    "    col_sum = dataarray[time].sum(axis=2,skipna=True)\n",
    "    col_mask = col_sum.where(col_sum.values<1,1)\n",
    "    return col_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load design and set paths to data\n",
    "nd = \"low_nd\"  # \"low_nd\" or \"high_nd\"\n",
    "ppe_path   = \"/gws/nopw/j04/carisma/eers/dycoms/{}/PPE/ppe\".format(nd)\n",
    "val_path   = \"/gws/nopw/j04/carisma/eers/dycoms/{}/VAL/val\".format(nd)\n",
    "extra_path = \"/gws/nopw/j04/carisma/eers/dycoms/{}/EXTRA/extra\".format(nd)\n",
    "base_path  = \"/gws/nopw/j04/carisma/eers/dycoms/{}/BASE/base/base.nc\".format(nd)\n",
    "design       = np.loadtxt(\"/home/users/eers/dycoms/designs/EmulatorInputsDesign2D.csv\",delimiter=\",\", skiprows=1)\n",
    "validation   = np.loadtxt(\"/home/users/eers/dycoms/designs/ValidationInputsDesign2D.csv\", delimiter=\",\", skiprows=1)\n",
    "extra_design = np.loadtxt(\"/home/users/eers/dycoms/designs/extra_points.csv\",delimiter=\",\")\n",
    "base = np.array([[-7.5, 8.5]])\n",
    "\n",
    "ppe_no   = 20\n",
    "val_no   = 8\n",
    "extra_no = 6\n",
    "base_no  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = OrderedDict()\n",
    "od[\"ppe\"]   = [ppe_no, ppe_path, design]\n",
    "od[\"val\"]   = [val_no, val_path, validation]\n",
    "od[\"extra\"] = [extra_no, extra_path, extra_design]\n",
    "od[\"base\"]  = [base_no, base_path, base]\n",
    "\n",
    "### Initialise np arrays ###\n",
    "last = np.empty((ppe_no+oat_no+val_no+extra_no+base_no, 3))\n",
    "mean = np.empty((ppe_no+oat_no+val_no+extra_no+base_no, 3))\n",
    "tend = np.empty((ppe_no+oat_no+val_no+extra_no+base_no, 3))\n",
    "teme = np.empty((ppe_no+oat_no+val_no+extra_no+base_no, 3))\n",
    "\n",
    "arrays = [last, mean, tend, teme]\n",
    "\n",
    "rwp     = np.empty((ppe_no+oat_no+val_no+extra_no+base_no, 3))\n",
    "rwp_end = np.empty((ppe_no+oat_no+val_no+extra_no+base_no, 3))\n",
    "surface_precip     = np.empty((ppe_no+oat_no+val_no+extra_no+base_no, 3))\n",
    "surface_precip_end = np.empty((ppe_no+oat_no+val_no+extra_no+base_no, 3))\n",
    "\n",
    "rain_arrays = [rwp, rwp_end, surface_precip, surface_precip_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "### Options ###\n",
    "include_spinup = False # See fine_spin and coarse_spin for setup\n",
    "\n",
    "first       = 0\n",
    "last        = -1\n",
    "coarse_spin = 2   # 1 hour = 1, 2 hours = 2\n",
    "fine_spin   = 111 # 1 hour = 55, 2 hours = 111\n",
    "coarse_ave  = 3\n",
    "fine_ave    = 111  \n",
    "\n",
    "### Loop through PPE datasets ###\n",
    "calc    = 'lwp_cloud'      # options: 'lwp_cloud', 'cloud_frac', 'rain'\n",
    "type_nd = \"lwp_low\"  # [lwp/cf/rain]_[low/high] but do lwp_total_low/high if doing lwp_total.\n",
    "i=0\n",
    "\n",
    "# lines=[]\n",
    "# lwp_scenes=[]\n",
    "type_timeseries=[]\n",
    "\n",
    "for key in od:\n",
    "    for j in range(od[key][0]):\n",
    "        k = j+1\n",
    "        nc = od[key][1] + str(k) + \"/\" + key + str(k) + \".nc\"\n",
    "        if key=='base':\n",
    "            nc = base_path \n",
    "        ds = xr.open_dataset(nc)\n",
    "        ds = ds_fix_dims(ds)\n",
    "            \n",
    "        if calc == 'lwp_cloud':\n",
    "            output_array, timeseries, tendency, times, lwp_masked_last, lwp_masked_arrs = lwp_cloud(ds)\n",
    "            time_hrs = times\n",
    "            for step, masked_arr in enumerate(lwp_masked_arrs):\n",
    "                np.savetxt(f\"{key}_scenes/scene_{step}.csv\",masked_arr.values, delimiter=',')\n",
    "\n",
    "            ### uncomment to save top-down scenes\n",
    "            # np.savetxt(\"lwp_scenes_last/lnd_lwp_scene_last_%s%s.csv\"%(key,k), lwp_masked_last.values, delimiter=',')\n",
    "        elif calc == 'cloud_frac':\n",
    "    \t    output_array, timeseries, tendency, times = clfrac(ds)\n",
    "    \t    time_hrs = times\n",
    "        elif calc == 'rain':\n",
    "    \t    output_array = rain(ds)\n",
    "        else:\n",
    "            print('Select calc')\n",
    "            break\n",
    "\n",
    "        if calc in ['cloud_frac','lwp_cloud']:\n",
    "    \t    for b, array in enumerate(arrays):\n",
    "                array[i, 0] = od[key][2][j][1]\n",
    "                array[i, 1] = od[key][2][j][0]\n",
    "                array[i, 2] = output_array[b]\n",
    "        elif calc == 'rain':\n",
    "    \t    for b, array in enumerate(rain_arrays):\n",
    "    \t        array[i, 0] = od[key][2][j][1]\n",
    "    \t        array[i, 1] = od[key][2][j][0]\n",
    "    \t        array[i, 2] = output_array[b]\n",
    "\n",
    "        ### uncomment to save ti\n",
    "        # if key=='ppe':\n",
    "        #     type_timeseries.append(timeseries)\n",
    "        # elif key=='base':\n",
    "        #     base=timeseries\n",
    "        # np.savetxt('./timeseries/{}/{}{}_timeseries.csv'.format(type_nd,key,str(k)),timeseries,delimiter=',')   # need type_nd instead of calc if not doing lwp_cloud\n",
    "        # np.savetxt('./timeseries/{}/{}{}_times.csv'.format(type_nd,key,str(k)),time_hrs,delimiter=',')\n",
    "        ds.close()\n",
    "        print(i)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc == 'rain':\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_rwp.csv\".format(nd, calc), rain_arrays[0], delimiter=\",\")\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_rwp_end.csv\".format(nd, calc), rain_arrays[1], delimiter=\",\")\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_surfpre.csv\".format(nd,calc), rain_arrays[2], delimiter=\",\")\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_surfpre_end.csv\".format(nd,calc), rain_arrays[3], delimiter=\",\")\n",
    "elif calc == 'lwp_smooth':\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_lwp_last.csv\".format(nd,calc), testing_arrays[0], delimiter=\",\")\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_lwp_mean_lasthr.csv\".format(nd,calc), testing_arrays[1], delimiter=\",\")\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_lwp_tend_last.csv\".format(nd,calc), testing_arrays[2], delimiter=\",\")\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_lwp_tend_ave.csv\".format(nd,calc), testing_arrays[3], delimiter=\",\")\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_lwp_tend_diff.csv\".format(nd,calc), testing_arrays[4], delimiter=\",\")\n",
    "else:\n",
    "    print(\"Saving..\")\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_last.csv\".format(nd,calc), arrays[0], delimiter=\",\")\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_mean.csv\".format(nd,calc), arrays[1], delimiter=\",\")\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_tend.csv\".format(nd,calc), arrays[2], delimiter=\",\")\n",
    "    np.savetxt(\"dycoms_data_{0}_{1}_teme.csv\".format(nd,calc), arrays[3], delimiter=\",\")\n",
    "#np.savetxt(\"ppe_{}_timeseries.csv\".format(type_nd), type_timeseries, fmt='%s', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Variability ###\n",
    "'''\n",
    "var_path = \"/gws/nopw/j04/carisma/eers/dycoms_sim/{}INT_VAR/\".format(nd)\n",
    "points = {\"thick\":\"Highest LWP\",\"kparam\":\"On $\\kappa$ line\", \"thin\":\"Lowest LWP\"}\n",
    "equiv = [\"ppe18\", \"ppe19\", \"ppe20\"]\n",
    "### Create lists ###\n",
    "e_last=[]\n",
    "e_mean=[]\n",
    "e_tend=[]\n",
    "e_teme=[]\n",
    "lines=[]\n",
    "i=0\n",
    "\n",
    "for point in points:\n",
    "    if point=='kparam':\n",
    "        colour = (238/255, 27/255, 155/255)\n",
    "        original = equiv[2]\n",
    "        tmp_run = 5\n",
    "    elif point=='thick':\n",
    "        colour = (255/255, 211/255, 29/255)\n",
    "        original = equiv[1]\n",
    "        tmp_run = 2\n",
    "    elif point=='thin':\n",
    "        colour = (26/255, 224/255, 203/255)\n",
    "        original = equiv[0]\n",
    "        tmp_run = 5\n",
    "\n",
    "    for i in range(tmp_run):# dropped to 4 extras + the 1 original run\n",
    "        if i==(tmp_run-1):\n",
    "            ds=xr.open_dataset(\"/gws/nopw/j04/carisma/eers/dycoms_sim/{0}PPE/{1}/{1}.nc\".format(nd,original))\n",
    "        else:\n",
    "            name = point + str(i+1)\n",
    "            nc = var_path + point + \"/\" + name + \"/\" + name + \".nc\" \n",
    "            ds = xr.open_dataset(nc)\n",
    "\n",
    "        ds = ds_fix_dims(ds)\n",
    "        hours = 8\n",
    "\n",
    "        if calc == 'lwp_total':\n",
    "            output_array, timeseries, tendency, times = lwp_total(ds, hours)\n",
    "            time_hrs = times\n",
    "        elif calc == 'lwp_cloud':\n",
    "            output_array, timeseries, tendency, times,lwp_masked = lwp_cloud(ds, hours)\n",
    "            time_hrs = times\n",
    "            #np.savetxt(\"lwp_scenes_values_intvar_%s.csv\"%(name), lwp_masked.values, delimiter=',')\n",
    "        elif calc == 'cloud_frac':\n",
    "            output_array, timeseries, tendency, times = clfrac(ds, hours)\n",
    "            time_hrs = times\n",
    "        else:\n",
    "            print(\"Select calc\")\n",
    "            break\n",
    "\n",
    "        #np.savetxt('./timeseries/{}/{}{}_timeseries.csv'.format(type_nd,point,str(i+1)), timeseries,delimiter=',')\n",
    "        #np.savetxt('./timeseries/{}/{}{}_times.csv'.format(type_nd,point,str(i+1)),time_hrs,delimiter=',')\n",
    "\n",
    "        e_last.append(output_array[0])\n",
    "        e_mean.append(output_array[1])\n",
    "        e_tend.append(output_array[2])\n",
    "        e_teme.append(output_array[3])\n",
    "    print(point + ' finished')    \n",
    "\n",
    "output_type=e_mean\n",
    "#thick_mean = \"{:.2f}\".format(np.mean(output_type[0:4]))\n",
    "#kparam_mean = \"{:.2f}\".format(np.mean(output_type[5:9]))\n",
    "#thin_mean = \"{:.2f}\".format(np.mean(output_type[10:14]))\n",
    "#thick_var = \"{:.2f}\".format(np.var(output_type[0:4]))\n",
    "#kparam_var = \"{:.2f}\".format(np.var(output_type[5:9]))\n",
    "#thin_var =\"{:.2f}\".format(np.var(output_type[10:14]))\n",
    "#labels = \"%s, $\\mu = %s,\\; \\sigma^{2} = %s$\"\n",
    "\n",
    "#np.savetxt('ensemble_%s.csv'%calc, [e_last, e_mean, e_tend, e_teme], delimiter=',')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe3/ppe3_1.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe3/ppe3_2.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe3/ppe3_3.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe3/ppe3_4.nc\n",
      "ds_last = original\n",
      "ppe3 finished\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe9/ppe9_1.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe9/ppe9_2.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe9/ppe9_3.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe9/ppe9_4.nc\n",
      "ds_last = original\n",
      "ppe9 finished\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe11/ppe11_1.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe11/ppe11_2.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe11/ppe11_3.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe11/ppe11_4.nc\n",
      "ds_last = original\n",
      "ppe11 finished\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe14/ppe14_1.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe14/ppe14_2.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe14/ppe14_3.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe14/ppe14_4.nc\n",
      "ds_last = original\n",
      "ppe14 finished\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe15/ppe15_1.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe15/ppe15_2.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe15/ppe15_3.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe15/ppe15_4.nc\n",
      "ds_last = original\n",
      "ppe15 finished\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe17/ppe17_1.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe17/ppe17_2.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe17/ppe17_3.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe17/ppe17_4.nc\n",
      "ds_last = original\n",
      "ppe17 finished\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe18/ppe18_1.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe18/ppe18_2.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe18/ppe18_3.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe18/ppe18_4.nc\n",
      "ds_last = original\n",
      "ppe18 finished\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe19/ppe19_1.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe19/ppe19_2.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe19/ppe19_3.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe19/ppe19_4.nc\n",
      "ds_last = original\n",
      "ppe19 finished\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe20/ppe20_1.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe20/ppe20_2.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe20/ppe20_3.nc\n",
      "/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/ppe20/ppe20_4.nc\n",
      "ds_last = original\n",
      "ppe20 finished\n"
     ]
    }
   ],
   "source": [
    "#calc='cloud_frac'\n",
    "calc='lwp_cloud'\n",
    "\n",
    "type_nd = \"lwp_cloud_low\"\n",
    "### Variability ###\n",
    "var_path = \"/gws/nopw/j04/carisma/eers/dycoms/low_nd/INT_VAR/\" #.format(nd)\n",
    "points = ['ppe3','ppe9','ppe11','ppe14','ppe15','ppe17','ppe18','ppe19','ppe20']\n",
    "\n",
    "### Create lists ###\n",
    "e_last=[]\n",
    "e_mean=[]\n",
    "e_tend=[]\n",
    "e_teme=[]\n",
    "lines=[]\n",
    "i=0\n",
    "for point in points:\n",
    "    for i in range(1,6):# dropped to 4 extras + the 1 original run\n",
    "        if i==(5):\n",
    "            ds=xr.open_dataset(f\"/gws/nopw/j04/carisma/eers/dycoms/low_nd/PPE/{point}/{point}.nc\")\n",
    "            print('ds_last = original')\n",
    "        else:\n",
    "            name = '{0}_{1}'.format(point, i)\n",
    "            nc = '{0}{1}/{2}.nc'.format(var_path,point,name)\n",
    "            print(nc)\n",
    "            ds = xr.open_dataset(nc)\n",
    "\n",
    "        ds = ds_fix_dims(ds)\n",
    "        #hours = 8\n",
    "\n",
    "        if calc == 'lwp_total':\n",
    "            output_array, timeseries, tendency, times = lwp_total(ds)\n",
    "            time_hrs = times   \n",
    "            e_mean.append(output_array[1])\n",
    "            e_teme.append(output_array[3])\n",
    "        elif calc == 'lwp_cloud':\n",
    "            output_array, timeseries, tendency, times, lwp_masked_last, lwp_diff = lwp_cloud(ds)\n",
    "            time_hrs = times\n",
    "            np.savetxt(\"lwp_scenes_last/lnd_lwp_scene_last_%s%s.csv\"%(point,i),lwp_masked_last.values, delimiter=',')\n",
    "            e_mean.append(output_array[1])\n",
    "            e_teme.append(output_array[3])\n",
    "        elif calc == 'cloud_frac':\n",
    "            output_array, timeseries, tendency, times = clfrac(ds)\n",
    "            time_hrs = times\n",
    "            #e_last.append(output_array[0])\n",
    "            #e_tend.append(output_array[2])\n",
    "            e_mean.append(output_array[1])\n",
    "            e_teme.append(output_array[3])\n",
    "        else:\n",
    "            print(\"Select calc\")\n",
    "            break\n",
    "\n",
    "        #np.savetxt('./timeseries/{}/{}{}_timeseries.csv'.format(type_nd,point,str(i+1)), timeseries,delimiter=',')\n",
    "        #np.savetxt('./timeseries/{}/{}{}_times.csv'.format(type_nd,point,str(i+1)),time_hrs,delimiter=',')\n",
    "\n",
    "    print(point + ' finished')    \n",
    "\n",
    "if calc=='lwp_total':\n",
    "    out_list = [e_mean, e_teme]\n",
    "elif calc=='cloud_frac':\n",
    "    #out_list = [e_last, e_tend]\n",
    "    out_list = [e_mean, e_teme]\n",
    "elif calc=='lwp_cloud':\n",
    "    out_list = [e_mean,e_teme]\n",
    "out_arr_T = np.array(out_list).T\n",
    "np.savetxt('ensemble_{}_mean.csv'.format(calc), out_arr_T, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list = [e_mean, e_teme]\n",
    "out_arr_T = np.array(out_list).T\n",
    "np.savetxt('ensemble_{}.csv'.format(calc), out_arr_T, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
